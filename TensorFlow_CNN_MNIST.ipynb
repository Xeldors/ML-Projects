{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf82de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TensorFlow\n",
    "import pandas as pd\n",
    "import os \n",
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ed23ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory= \"C:/Users/sergi/Documents/Py\"\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc3c5445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset from Keras\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# Split into training and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "(x_train2, y_train2), (x_test2, y_test2) = mnist.load_data()\n",
    "\n",
    "#Storing locally an image\n",
    "# Select an image from the dataset (e.g., the first image)\n",
    "image = x_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e756e673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the image corresponds to a 5\n"
     ]
    }
   ],
   "source": [
    "###MNIST input variable example\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "# img = mpimg.imread('mnist_image.png')\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')  # Optional: turn off the axis\n",
    "plt.show()\n",
    "print(f\"the image corresponds to a {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c9e25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##We are telling we want 3 hidden layers each with 500 nodes. The final output layer will have 10 nodes\n",
    "layer_1_nodes = 500\n",
    "layer_2_nodes = 500\n",
    "layer_3_nodes = 500\n",
    "output_nodes = len(set(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8bb65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##One Hot enconding the sets: \n",
    "y_train = tf.keras.utils.to_categorical(y_train, len(set(y_train)))#10 Categories 0 to 9 that can be defined as len(set(y_train))\n",
    "y_test = tf.keras.utils.to_categorical(y_test, len(set(y_test)))\n",
    "##One hot encoding transforms the variables into different outputs inside a vector. As such our CNN will have 10 outputs. Eg if the output is (0,0,1,0,0,0,0,0,0,0), means that the output is a 2.\n",
    "#The CNN will be in the format of such vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "275b8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Defining the hyperparameters of the CNN\n",
    "learning_rate = 0.0001  ###The change applied on the weights partial derivatives\n",
    "batch_size = 100 ## We are telling the CNN that every 100 images revalance the weights (this saves memory instead of updating weights for all the set)\n",
    "update_step = 10 ###   We are telling Python after how many epochs print an update of the training process. In this case after 10 epochs (10 times the whole data goes through the network, or 10 loop)\n",
    "validation_nr = 0.2##20% of the data will be used for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b53d3159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of x_train: 60000 images with 28 x 28 pixels\n"
     ]
    }
   ],
   "source": [
    "print(\"Original shape of x_train:\", x_train.shape[0],\"images with\",x_train.shape[1], \"x\",  x_train.shape[2], \"pixels\")  \n",
    "\n",
    "###Defining shape of inpuys\n",
    "input_shape = ((x_train.shape[1]*x_train.shape[2],))  # Flattened input images 784 or 28 pixels x 28 pixels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0978d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##We are transforming the input variables into vectors\n",
    "x_train = x_train.reshape(-1, 28 * 28).astype('float32') # Reshape transform into vectors an then we transform each of the vector elements into a 32 byte float \n",
    "x_test = x_test.reshape(-1, 28 * 28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee9b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=input_shape),  # Input layer\n",
    "    tf.keras.layers.Dense(layer_1_nodes, activation='relu'),  # Hidden layer with 500 units with relu or sigmoid functions\n",
    "    tf.keras.layers.Dense(layer_2_nodes, activation='relu'),  # Hidden layer with 500 units with relu or sigmoid functions\n",
    "    tf.keras.layers.Dense(layer_3_nodes, activation='relu'),  # Hidden layer with 500 units with relu or sigmoid functions\n",
    "    tf.keras.layers.Dense(output_nodes, activation='softmax')  # Output layer with softmax activation with softmax\n",
    "])\n",
    "\n",
    "\n",
    "# ReLU (Rectified Linear Unit) is an activation function that outputs zero for negative inputs and the input value itself for positive inputs. It is widely used in hidden layers of neural networks due to its efficiency and ability to avoid the vanishing gradient problem.\n",
    "# Sigmoid is an activation function that maps inputs to an output between 0 and 1, making it suitable for binary classification tasks but less effective for deep networks due to its tendency to cause vanishing gradients.\n",
    "# softmax;: The softmax activation function is used primarily in the output layer of a neural network to convert raw logits (scores) into probabilities. It is defined as:\n",
    "#softmat functio Z(i)= e(x i)/sum of i (e(x)) where i is each of the differenty final hidden layers outputs\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ba50b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer_SGD= tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer_SGD, \n",
    "              loss='categorical_crossentropy',    ## Btter than MSE  thus is - sum z(i)*log(pi) where Pi is the softmax output and yi is the real output\n",
    "              metrics=['accuracy'])   ##Accuracy as our main goodness of fit measure  \n",
    "\n",
    "\n",
    "##Other Loss functions include: \n",
    "# Sparce Categorical Cross-Entropy: better used when output target are integers and not one hot encoded vectors: sparse_categorical_crossentropy\n",
    "# KL Divergence: Measures how one probability distribution diverges from a second, expected probability distribution = sum p(i)* log(pi/qi): kld\n",
    "# Binary Cross-Entropy: Better used 1 or 0 output: binary_crossentropy\n",
    "#MAE: regressions: \"mae\"\n",
    "# MSE: regressions: mse\n",
    "\n",
    "##Custom loss functions: \n",
    "# def custom_loss(y_true, y_pred):\n",
    "#     return tf.reduce_mean(tf.square(y_true - y_pred))  # Example: Mean Squared Error\n",
    "#loss= custom_loss\n",
    "\n",
    "#Optimisers rather than adam_ \n",
    "#Stochastic Gradient Descent (SGD)\n",
    "#  tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True) Momentum is optional nesterov=True is also optional\n",
    "#adam includes momentum and variances on the weight optimisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "595ea0c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6460 - loss: 9.0116 - val_accuracy: 0.8643 - val_loss: 1.9462\n",
      "Epoch 2/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8720 - loss: 1.6343 - val_accuracy: 0.8898 - val_loss: 1.3556\n",
      "Epoch 3/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 1.1609 - val_accuracy: 0.8968 - val_loss: 1.1780\n",
      "Epoch 4/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9165 - loss: 0.8237 - val_accuracy: 0.9046 - val_loss: 1.0145\n",
      "Epoch 5/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.6717 - val_accuracy: 0.9113 - val_loss: 0.9467\n",
      "Epoch 6/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9355 - loss: 0.5668 - val_accuracy: 0.9163 - val_loss: 0.8877\n",
      "Epoch 7/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9407 - loss: 0.4693 - val_accuracy: 0.9188 - val_loss: 0.8282\n",
      "Epoch 8/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9465 - loss: 0.4049 - val_accuracy: 0.9199 - val_loss: 0.7946\n",
      "Epoch 9/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9532 - loss: 0.3392 - val_accuracy: 0.9235 - val_loss: 0.7658\n",
      "Epoch 10/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.2786 - val_accuracy: 0.9248 - val_loss: 0.7380\n",
      "Epoch 11/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9626 - loss: 0.2491 - val_accuracy: 0.9250 - val_loss: 0.7271\n",
      "Epoch 12/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9660 - loss: 0.2089 - val_accuracy: 0.9278 - val_loss: 0.7065\n",
      "Epoch 13/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9665 - loss: 0.2091 - val_accuracy: 0.9275 - val_loss: 0.7074\n",
      "Epoch 14/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9708 - loss: 0.1755 - val_accuracy: 0.9278 - val_loss: 0.6854\n",
      "Epoch 15/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9746 - loss: 0.1509 - val_accuracy: 0.9300 - val_loss: 0.6753\n",
      "Epoch 16/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9766 - loss: 0.1336 - val_accuracy: 0.9299 - val_loss: 0.6675\n",
      "Epoch 17/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.1135 - val_accuracy: 0.9312 - val_loss: 0.6606\n",
      "Epoch 18/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.1015 - val_accuracy: 0.9315 - val_loss: 0.6519\n",
      "Epoch 19/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.0912 - val_accuracy: 0.9290 - val_loss: 0.6723\n",
      "Epoch 20/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9839 - loss: 0.0839 - val_accuracy: 0.9304 - val_loss: 0.6460\n",
      "Epoch 21/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 0.0720 - val_accuracy: 0.9302 - val_loss: 0.6445\n",
      "Epoch 22/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0714 - val_accuracy: 0.9320 - val_loss: 0.6361\n",
      "Epoch 23/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0605 - val_accuracy: 0.9323 - val_loss: 0.6358\n",
      "Epoch 24/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0513 - val_accuracy: 0.9312 - val_loss: 0.6349\n",
      "Epoch 25/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0482 - val_accuracy: 0.9327 - val_loss: 0.6335\n",
      "Epoch 26/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0402 - val_accuracy: 0.9318 - val_loss: 0.6370\n",
      "Epoch 27/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0385 - val_accuracy: 0.9329 - val_loss: 0.6284\n",
      "Epoch 28/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0352 - val_accuracy: 0.9333 - val_loss: 0.6243\n",
      "Epoch 29/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0329 - val_accuracy: 0.9331 - val_loss: 0.6311\n",
      "Epoch 30/30\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0294 - val_accuracy: 0.9327 - val_loss: 0.6268\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "CNN_fit = model.fit(\n",
    "    x_train, y_train,          # Training data and labels\n",
    "    epochs=30,                 # Number of epochs\n",
    "    batch_size=batch_size,             # Mini-batch size\n",
    "    validation_split=validation_nr       # Fraction of training data to be used for validation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f774f370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.7839\n",
      "Test Loss: 0.6654059886932373\n",
      "Test Accuracy: 0.9284999966621399\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {test_loss}') ###Loss value on th last dataset\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ef088f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "First prediction: [1.5043760e-16 2.7625313e-23 4.6852031e-18 6.2481568e-08 1.6448243e-25\n",
      " 2.2771174e-15 4.8678571e-36 9.9999988e-01 2.1390444e-18 2.3754182e-22]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Example: Print the first prediction\n",
    "print(f'First prediction: {predictions[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccfbfbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "##Transforming Prediction into numbers\n",
    "\n",
    "def output_CNN(x):\n",
    "    def roundes(y):\n",
    "        y=list(y)\n",
    "        return y.index(max(y))\n",
    "    outputs = []\n",
    "    for i in x:\n",
    "        xx = roundes(i)  # Get the index of 1 in the rounded list\n",
    "        outputs.append(xx)  # Append the result to outputs\n",
    "    return outputs\n",
    "\n",
    "Outputs_test=output_CNN(predictions)\n",
    "Outputs_train=output_CNN(model.predict(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4536fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the CNN predict the image as 3\n"
     ]
    }
   ],
   "source": [
    "####Last step is to check if the CNN correctly predicts a random image of the databank\n",
    "import random\n",
    "\n",
    "imagetoshow= random.randint(1, len(Outputs_test))\n",
    "image_test=x_test2[imagetoshow]\n",
    "plt.imshow(image_test, cmap='gray')\n",
    "plt.axis('off')  # Optional: turn off the axis\n",
    "plt.show()\n",
    "print(f\"the CNN predict the image as {Outputs_test[imagetoshow]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
