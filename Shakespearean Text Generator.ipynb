{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f8d72048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "directory=\"C:/Users/sergi/Documents/Py\"\n",
    "os.chdir(directory )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b794850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting data and storing\n",
    "shakespeare_url=\"https://homl.info/shakespeare\"\n",
    "filepath=tf.keras.utils.get_file(\"shakespeare.txt\",shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ee6ab70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee81dc3",
   "metadata": {},
   "source": [
    "**Vectorisation**\n",
    "\n",
    "The text is getting vectorised with each word mapped to a token ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "601a24ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total numer of chars: 1115394\n"
     ]
    }
   ],
   "source": [
    "text_vec_layer=tf.keras.layers.TextVectorization(split=\"character\",standardize=\"lower\")\n",
    "text_vec_layer.adapt([shakespeare_text])\n",
    "encoded=text_vec_layer([shakespeare_text])[0]\n",
    "\n",
    "\n",
    "n_tokens=text_vec_layer.vocabulary_size() \n",
    "\n",
    "dataset_size=len(encoded) \n",
    "print(f\"total numer of chars: {dataset_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07aeb1c",
   "metadata": {},
   "source": [
    "**Dataset of windows**\n",
    "\n",
    "Turning the training data into a dataset of windows in which a RNN can be use to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26d1cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "    ds=tf.data.Dataset.from_tensor_slices(sequence)  # Going to tensor to dataset\n",
    "    ds=ds.window(length+1,shift=1,drop_remainder=True) # creating a window objects of length X. drop_remainder=True ensures the last window does not have extra elements  \n",
    "    ds=ds.flat_map(lambda window_ds:window_ds.batch(length+1)) # Reconverting each window object into a tensor\n",
    "    if shuffle==True:\n",
    "        ds=ds.shuffle(buffer_size=100_000, seed=seed) #Shuffling the windows. Buffer size that is large ensures a better randomization.\n",
    "    ds=ds.batch(batch_size) # The tensor dataset is grouped into batches of Y size\n",
    "    return ds.map(lambda window:(window[:,:-1],window[:,1:])).prefetch(1) # map applied the funcion to the entire dataset. We are creating inputs and outputs sequences\n",
    "#The obtained is a tf dataset of tensors with inputs that are sequenced of x len and outputs that seguences of x+1 len.\n",
    "# In other words the outpust are the next character following the inputs. So if input is the text vectorized text[:100], output is text[1:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "156e0ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating training, testimg and validation\n",
    "\n",
    "#We are reducing the amount of data so it performs the computations faster\n",
    "\n",
    "length=100\n",
    "tf.random.set_seed(42)\n",
    "train_set=to_dataset(encoded[:1_000_000], length=length, shuffle=True, seed=42)\n",
    "valid_set=to_dataset(encoded[1_000_000:1_050_000], length=length)\n",
    "test_set=to_dataset(encoded[1_050_000:], length=length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ef2ad8",
   "metadata": {},
   "source": [
    "**Building and training a Char-RNN  Model**\n",
    "\n",
    "The model will predict the next character in a word. Such that with, hello: input: \"hell\", output: \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "af02e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2130s\u001b[0m 68ms/step - accuracy: 0.5695 - loss: 1.3957 - val_accuracy: 0.5268 - val_loss: 1.7576\n",
      "Epoch 2/3\n",
      "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2001s\u001b[0m 64ms/step - accuracy: 0.6365 - loss: 1.1442 - val_accuracy: 0.5311 - val_loss: 1.7898\n",
      "Epoch 3/3\n",
      "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2060s\u001b[0m 66ms/step - accuracy: 0.6416 - loss: 1.1249 - val_accuracy: 0.5310 - val_loss: 1.8104\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16), # This is a 3D vector with input dim equaling the window lenghth, output dim and btach size\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(200, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(180, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_ckpt=tf.keras.callbacks.ModelCheckpoint(\"/shakespeare/shakesparemodel.keras\",monitor=\"val_accuracy\",save_best_only=True)\n",
    "history=model.fit(train_set, validation_data=valid_set, epochs=3, callbacks=[model_ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dc45f799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2041/2041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - accuracy: 0.5307 - loss: 1.8285\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01ca85",
   "metadata": {},
   "source": [
    "**Generating fake shakespearean text**\n",
    "\n",
    "Weare sampling the the next character randomly with a probability equal to the estimated model probability.\n",
    "In this sense we are feeding into the text the estimated character with a certain probability of being chosen the one with the highest softmax output. \n",
    "This certain probability is called temperature and the higher the more likely to get the top probability output of the softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727fa0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs=tf.math.log([[0.4,0.5,0.1]])# Probabilities of 40, 50 and 10\n",
    "tf.random.set_seed(42)\n",
    "tf.random.categorical(log_probs, num_samples=8 )# We are drawing 8 random samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def netx_char(text, temperature=1):\n",
    "    y_proba=model_prob(text, model)\n",
    "    rescaled_logits=tf.math.log(y_proba)/temperature\n",
    "    char_id=tf.random.categorical(rescaled_logits, num_samples=1)[0,0]\n",
    "    return text_vec_layer.get_vocabulary()[char_id+2]\n",
    "##This function gets the ouput of the RNN and then takes randomly one of the outputs (highest temperature more random) and then gives us the character in form of token id.  Finally looks for the tokenn id in the vocab vectord and returns the correct character. \n",
    "\n",
    "def extended_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text+=next_char(text, temperature)\n",
    "    return text\n",
    "#This function generates text of len 50 characters\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc35f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "print(extended_text(\"To be or not to be\"), temperature=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
