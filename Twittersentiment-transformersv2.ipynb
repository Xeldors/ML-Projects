{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1192de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as  tf #Required to fit Neural Networks\n",
    "import os #Required to address wd\n",
    "import pandas as pd #Required for data manipulation\n",
    "import numpy as np #Required for mathematical operations\n",
    "import re #Required for reshaping the tweets without punctuation signs\n",
    "import string#Required for reshaping the tweets without punctuation signs\n",
    "from tensorflow.keras.layers import TextVectorization #Required for text vectorisation\n",
    "import sklearn as sk #Required for accuracy metrics\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b814c625",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large\\textbf{Twitter/X sentiment analysis}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd899732",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\textbf{Problem definition:}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea14cfa",
   "metadata": {},
   "source": [
    "$\n",
    "\\small\\text{Companies are constantly launching and testing new products, usually teasing them on Twitter/X. }\n",
    "$\n",
    "$\n",
    "\\small\\text{The amount of tweets that react to these company posts can be very large, making the overall sentiment difficult to measure. }\n",
    "$\n",
    "$\n",
    "\\small\\text{Millions of tweets can react to a single post, it is virtually impossible for a company to read through all these tweets.\n",
    "}\n",
    "$\n",
    "$\n",
    "\\small \\text{This ML/AI solution can help companies by quickly analyzing tweets and determining the overal positiveness of the market towards a product.}\n",
    "$\n",
    "$\n",
    "\\small \\text{Hence, a company can theoretically retrieve or download all the tweets with a certain hashtag, run them through the model, and average the results} \n",
    "$\n",
    "$\n",
    "\\small \\text{ to get a quick picture of the overall market sentiment towards the teased product.\n",
    "}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2723e2ff",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Data and assumptions of the project:}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c111db",
   "metadata": {},
   "source": [
    "$\n",
    "\\small\\text{Data is a subset of the sentiment140 open dataset from tensorflow hub.}\n",
    "\\\n",
    "\\href{https://www.tensorflow.org/datasets/catalog/sentiment140}{TFSentiment140}\n",
    "$\n",
    "$\n",
    "\\small\\text{The data file format has 6 fields:}\n",
    "\\\\\n",
    "$\n",
    "$\n",
    "\\small\\text{ - The polarity of the tweet (0 = negative, 4 = positive)}  \n",
    "$\n",
    "\n",
    "$\n",
    "\\small\\text{ - The id of the tweet (2087)}  \n",
    "$\n",
    "\n",
    "$\n",
    "\\small\\text{ - The date of the tweet (Sat May 16 23:58:44 UTC 2009)}  \n",
    "$\n",
    "\n",
    "$\n",
    "\\small\\text{ - The query (lyx). If there is no query, then this value is NO_QUERY.}  \n",
    "$\n",
    "\n",
    "$\n",
    "\\small\\text{ - The user that tweeted}  \n",
    "$\n",
    "\n",
    "$\n",
    "\\small\\text{ - The text of the tweet (Lyx is cool)}\n",
    "$\n",
    "\n",
    "$\n",
    "\\small\\text{The dataset used can be retrieved directly from:}\n",
    "\\\n",
    "\\href{https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/datasets/sentiment140/dummy_data/training.1600000.processed.noemoticon.csv}{CSVLinkData}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba20652",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Data Citation:}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26eb679",
   "metadata": {},
   "source": [
    "$\n",
    "\\small{Go, Alec, Bhayani, Richa, and Huang, Lei.} \n",
    "$\n",
    "$\n",
    "\\small{\\textit{\"Twitter Sentiment Classification using Distant Supervision.\"(2009). } Available:} \n",
    "$\n",
    "$\n",
    "\\href{http://help.sentiment140.com/home}{http://help.sentiment140.com/home}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c857eafa",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Implementation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9b5737",
   "metadata": {},
   "source": [
    "$$\n",
    "\\small{\\text{- Uploading the data, resizing and splitting it -}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "491ca455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the working directory\n",
    "directory=\"C:/Users/sergi/Documents/Py/twittersentiment\"\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366d316e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "training_val=pd.read_excel(\"training.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9726a81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.467810e+09</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.467811e+09</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.467811e+09</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.467811e+09</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.467811e+09</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment            id                          date     query  \\\n",
       "0          0  1.467810e+09  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1.467811e+09  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1.467811e+09  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1.467811e+09  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1.467811e+09  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                              tweet  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showcasing and cleaning the data\n",
    "training_val=training_val[[\"sentiment\",\"id\",\"date\",\"query\",\"user\",\"tweet\"]]\n",
    "training_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "535c5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train=[str(i) for i in training_val[\"tweet\"].tolist()]\n",
    "outputs = [0 if i == 0 else 1 if i == 4 else i for i in training_val[\"sentiment\"].tolist()]\n",
    "Data=pd.DataFrame({\"inputs\":tweets_train, \"outputs\":outputs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f4395f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of positive tweets: 249953, Nr of negative tweets:798622, Total Nr of Tweets:1048575\n"
     ]
    }
   ],
   "source": [
    "#Summarising data\n",
    "nr_positive=len(Data[Data[\"outputs\"]==1])\n",
    "nr_negative=len(Data[Data[\"outputs\"]==0])\n",
    "print(f\"Nr of positive tweets: {nr_positive}, Nr of negative tweets:{nr_negative}, Total Nr of Tweets:{len(Data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18f956c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has been resized to have the same amount of positive and negative tweets: 224957 for positive, and 224957 for negative\n",
      "For the testing data we are using: 24996 for positive, and 24996 for negative\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@LaurenConrad I can't believe he lost... I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Larry's out for the night at a Halo party with...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chase has been home for an hour, and has alrea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I sliced my thumb pretty bad today... but I do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@megkautz ring tailed lemurs are my favorite n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  outputs\n",
       "0  @LaurenConrad I can't believe he lost... I'm s...        0\n",
       "1  Larry's out for the night at a Halo party with...        0\n",
       "2  Chase has been home for an hour, and has alrea...        0\n",
       "3  I sliced my thumb pretty bad today... but I do...        0\n",
       "4  @megkautz ring tailed lemurs are my favorite n...        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reducing the dataset to 50000 positive and negative (this is done to avoid excessive training time)\n",
    "shuffled_positive = Data[Data[\"outputs\"]==1].sample(frac=1, random_state=10).reset_index(drop=True)\n",
    "shuffled_negative = Data[Data[\"outputs\"]==0].sample(frac=1, random_state=10).reset_index(drop=True)\n",
    "\n",
    "shuffled_positive_train=shuffled_positive.iloc[:int(nr_positive*0.9),:]\n",
    "shuffled_negative_train=shuffled_negative.iloc[:int(nr_positive*0.9),:]\n",
    "\n",
    "shuffled_positive_test=shuffled_positive.iloc[int(nr_positive*0.9):,:]\n",
    "shuffled_negative_test=shuffled_negative.iloc[int(nr_positive*0.9):len(shuffled_positive),:]\n",
    "\n",
    "\n",
    "train_data=pd.concat([shuffled_positive_train,shuffled_negative_train], axis=0).sample(frac=1, random_state=10).reset_index(drop=True)\n",
    "test_data=pd.concat([shuffled_positive_test,shuffled_negative_test], axis=0).sample(frac=1, random_state=10).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(f\"The training data has been resized to have the same amount of positive and negative tweets: {len(shuffled_positive_train)} for positive, and {len(shuffled_negative_train)} for negative\")\n",
    "print(f\"For the testing data we are using: {len(shuffled_positive_test)} for positive, and {len(shuffled_negative_test)} for negative\")\n",
    "\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4020f853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'outputs'],\n",
       "    num_rows: 449914\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=Dataset.from_pandas(train_data)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52702e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1030, 10294, 8663, 12173, 1045, 2064, 1005, 1056, 2903, 2002, 2439, 1012, 1012, 1012, 1045, 1005, 1049, 2061, 6517, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', '@', 'lauren', '##con', '##rad', 'i', 'can', \"'\", 't', 'believe', 'he', 'lost', '.', '.', '.', 'i', \"'\", 'm', 'so', 'sad', '.', '[SEP]']\n",
      "@LaurenConrad I can't believe he lost... I'm so sad. \n",
      "[CLS] @ laurenconrad i can ' t believe he lost... i ' m so sad. [SEP]\n"
     ]
    }
   ],
   "source": [
    "#BERT\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_cpkt=\"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_cpkt)\n",
    "\n",
    "# ##Alternatively: \n",
    "# from transformers import DistilBertTokenizer\n",
    "# distilbert_tokenizer=DistilBertTokenizer.from_pretrained(model_cpkt)\n",
    "\n",
    "#Example\n",
    "encoded_text_example=tokenizer(train_data[\"inputs\"][0])\n",
    "print(encoded_text_example)\n",
    "\n",
    "#see where each id maps to what word - Essentially we see the tokens\n",
    "print(tokenizer.convert_ids_to_tokens(encoded_text_example.input_ids))\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded_text_example.input_ids)\n",
    "#Original text\n",
    "print(train_data[\"inputs\"][0])\n",
    "\n",
    "#Convert token to strings\n",
    "print(tokenizer.convert_tokens_to_string(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1bc9afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/449914 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenising the  whole training set \n",
    "def tokenize(batch): \n",
    "    return tokenizer(batch[\"inputs\"], padding=True, truncation=True)\n",
    "\n",
    "encoded_train= train_data.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4d95c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'outputs', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 449914\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7b0ed",
   "metadata": {},
   "source": [
    "Feeding our data into distilbert and obtaining the last hidden output for the model. \n",
    "This output will be fet into a dense network that will give us a sigmoid probability if the inputs has a positive or a negative sentiment. \n",
    "\n",
    "Below I specify the code for tf and torch inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b63985",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Obtaining the hidden states for the model using BERT. In the sense of an encoder-decoder model this would be th equivalent of the econder part.\n",
    "\n",
    "##Pytorch\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_checkpoint).to(device)\n",
    "\n",
    "# Function to extract hidden states\n",
    "def extract_hidden_states(batch):\n",
    "    # Tokenize and pad the inputs\n",
    "    # Convert input_ids and attention_mask to tensors and pad them to the same length\n",
    "    inputs = tokenizer(batch[\"inputs\"], padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    \n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "    \n",
    "    # Forward pass through the model without gradient tracking\n",
    "    with torch.no_grad():\n",
    "        # Get the last hidden state from the DistilBERT model\n",
    "        last_hidden_state = model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "    \n",
    "    # Return the hidden state for the [CLS] token (first token in the sequence)\n",
    "    return {\"hidden_state\": last_hidden_state[:, 0].cpu().numpy()}\n",
    "\n",
    "# Apply the function to extract hidden states using .map()\n",
    "train_hidden = train_data.map(extract_hidden_states, batched=True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95535677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sergi\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sergi\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/449914 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "modelbert = TFAutoModel.from_pretrained(model_checkpoint)\n",
    "\n",
    "def extract_hidden_states_from_text(text):\n",
    "    # Tokenize and pad the input\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"tf\", max_length=512)\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    \n",
    "    # Forward pass through the model to get the last hidden state\n",
    "    last_hidden_state = modelbert(input_ids=input_ids, attention_mask=attention_mask)[0]  # [0] for last_hidden_state\n",
    "    \n",
    "    # Return the hidden state for the [CLS] token (first token in the sequence)\n",
    "    return last_hidden_state[:, 0].numpy()\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract hidden states\n",
    "def extract_hidden_states(batch):\n",
    "    # Tokenize and pad the inputs\n",
    "    inputs = tokenizer(batch[\"inputs\"], padding=True, truncation=True, return_tensors=\"tf\", max_length=512)\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    \n",
    "    # Forward pass through the model without gradient tracking\n",
    "    # tf.function can be used for optimizing the forward pass, but it is not strictly necessary here\n",
    "    last_hidden_state = modelbert(input_ids=input_ids, attention_mask=attention_mask)[0]  # [0] for last_hidden_state\n",
    "    \n",
    "    # Return the hidden state for the [CLS] token (first token in the sequence)\n",
    "    return {\"hidden_state\": last_hidden_state[:, 0].numpy()}\n",
    "\n",
    "# Example of how you might apply this to your dataset\n",
    "# Assuming train_data is a Dataset object with 'inputs' as one of the columns\n",
    " train_hidden = train_data.map(extract_hidden_states, batched=True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "620c09a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'outputs'],\n",
       "    num_rows: 449914\n",
       "})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aac3771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'outputs', 'hidden_state'],\n",
       "    num_rows: 449914\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abefcb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming hidden states into Keras tensorflow \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_hidden[\"hidden_state\"], train_hidden[\"outputs\"])).batch(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e2343d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sizes for the training and validation datasets\n",
    "dataset_size = len(list(train_dataset))  # Convert to list to get the size of the dataset\n",
    "train_size = int(0.9 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_split = train_dataset.take(train_size)\n",
    "val_split = train_dataset.skip(train_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f75cf436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden States Shape: (1000, 768)\n",
      "Outputs Shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "for example in val_split.take(1):\n",
    "    print(\"Hidden States Shape:\", example[0].shape)  # Should be (batch_size, 768)\n",
    "    print(\"Outputs Shape:\", example[1].shape)         # Should be (batch_size,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07776ef",
   "metadata": {},
   "source": [
    "Decoder part of the model: \n",
    "\n",
    "Creating a keras dense model were the last hidden output from the bert model is passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963006ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(500, activation='relu'),  # Ensure the input shape matches\n",
    "    tf.keras.layers.Dense(200, activation='relu'),  # Ensure the input shape matches\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid for binary classification\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',  # Use binary_crossentropy for binary classification\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_split, epochs=10, validation_data=val_split)                                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f42251af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7869 - loss: 0.4455\n",
      "Categorical Cross entropy Loss Train set: 0.44335004687309265\n",
      "Train set Accuracy: 0.7881895899772644\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7719 - loss: 0.4731\n",
      "Categorical Cross entropy Loss Validation Set: 0.4682205617427826\n",
      "Validation set Accuracy: 0.7738292813301086\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(train_split)\n",
    "print(f'Categorical Cross entropy Loss Train set: {train_loss}') ###Loss value on th last dataset\n",
    "print(f'Train set Accuracy: {train_accuracy}')\n",
    "\n",
    "val_loss, val_accuracy = model.evaluate(val_split)\n",
    "print(f'Categorical Cross entropy Loss Validation Set: {val_loss}') ###Loss value on th last dataset\n",
    "print(f'Validation set Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58157135",
   "metadata": {},
   "source": [
    "Defining a Function that will apply the hiddent state of the BERT model to out trained dense network.\n",
    "The end product is a function that tell us if a tweet has postive or negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "774b0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function that tells me if a tweet is good or bad\n",
    "def good_bad_twee(text): \n",
    "    text_hid=extract_hidden_states_from_text(text)\n",
    "    predictions=model.predict([text_hid])\n",
    "    if predictions>0.5: \n",
    "        print(text + \":is positive\")\n",
    "    else:\n",
    "        print(text +\"is negative\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "96167245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "This is fantastic!!:is positive\n"
     ]
    }
   ],
   "source": [
    "tweet = \"This is fantastic!!\"\n",
    "good_bad_twee(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dfbaeba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "This is fuckedup!!is negative\n"
     ]
    }
   ],
   "source": [
    "tweet = \"This is fuckedup!!\"\n",
    "good_bad_twee(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "07ecba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Great day for you:is positive\n"
     ]
    }
   ],
   "source": [
    "tweet = \"Great day for you\"\n",
    "good_bad_twee(tweet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
